{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pingouin as pg\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unclear proportion:  0.08915145005370569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43691/2428368908.py:37: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  df['yes'] = df['a'].str.contains(pat=r'\\b(yes)\\b', regex=True)\n",
      "/tmp/ipykernel_43691/2428368908.py:38: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  df['no'] = df['a'].str.contains(pat=r'\\b(no)\\b', regex=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "60c4691787a92ea2736450d4    30\n",
       "62348a574fc351980c10604d    30\n",
       "62ee4337445b044245a71185    30\n",
       "576745749dcd970001dbdd0b    30\n",
       "5f047ad3b4eb766c94bb20a7    30\n",
       "5f7e292bc98b530dc2c16c4d    30\n",
       "5d2e06eb64970300169c8fdf    30\n",
       "6131f6711c0d96f6f1fb04af    30\n",
       "60e962df6e5dab0795cae4c6    30\n",
       "626d611a6d646b36a7721304    30\n",
       "60c9395dd973ea5ebe0ea6ad    30\n",
       "60fff225fb2da6129caf029a    30\n",
       "5e482352020bde2be9b4ded1    30\n",
       "5f5bb19873fa1f341a4eaa3b    30\n",
       "5e249bc4292336713bc67cc3    30\n",
       "62cd7356ccb2b76b1a9d7083    30\n",
       "5c7093155ba5060001ce5f1a    30\n",
       "5b52fb6cb3c9400001f23bb5    30\n",
       "60dd669a2f3a194e6ca03757    30\n",
       "5c366fc38821900001b38b67    30\n",
       "5e25d8927ea9c201db8a2fd9    30\n",
       "60fc7a2f25df85c07054ce04    30\n",
       "627a83761978ca1469e6e750    30\n",
       "62ed82df460d7a1d965535b9    30\n",
       "6294990ec8b96a6df740a8b8    30\n",
       "60cf508d719c605fdbb3387e    30\n",
       "615dfbfde9859801c5fc4b87    30\n",
       "5f2b348c2eeba5556920b2d5    30\n",
       "5ea07fc202b8bd05bb59bc38    30\n",
       "5b661bc3259daf00019369f2    29\n",
       "60d98308ecc4c4e732c86a71    29\n",
       "5e8cb846e94a4406307d6da2     2\n",
       "notfound                     1\n",
       "Name: prolific_id, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "foldernames = [\n",
    "    './GPT3/cushman/items-07_07_2022__19:58:42',\n",
    "    './GPT3/cushman/items-003_2023',\n",
    "    './HUMANS/',\n",
    "]\n",
    "filenames = ['/results.csv', '/results.csv', '/cushman.csv']\n",
    "labels = ['gpt-002', 'gpt-003', 'human']\n",
    "dfs = []\n",
    "dfs_with_unclear = []\n",
    "\n",
    "dataset = json.load(open('data/cushman/items.json'))\n",
    "dataset = pd.DataFrame(dataset)\n",
    "for label, foldername, fname in zip(labels, foldernames, filenames):\n",
    "    df = pd.read_csv(open(foldername+fname, 'r'))\n",
    "    df['exp'] = label\n",
    "    if 'answer' in df.columns:\n",
    "        df['a'] = df['answer']\n",
    "    df['a'] = df['a'].str.lower()\n",
    "    df = df[df['q_id']==0]\n",
    "    df = df[~df['item_id'].isin([1, 2])]\n",
    "    for i in df['item_id'].unique():\n",
    "        if i not in (1, 2):\n",
    "\n",
    "            df.loc[df['item_id']==i, 'title'] = \\\n",
    "                str(dataset[dataset['id']==i]['title'].unique()[0])[2:]\n",
    "            df.loc[df['item_id']==i, 'cond'] = \\\n",
    "                str(dataset[dataset['id']==i]['title'].unique()[0])[:2]\n",
    "\n",
    "    df['principle'] = ''\n",
    "    df['principle'] = df['principle'].astype('object')\n",
    "    df.loc[df['cond'].str.contains('ik|ci|fk|cf'), 'principle'] += ' action '\n",
    "    df.loc[df['cond'].str.contains('l'), 'principle'] += ' inaction '\n",
    "    df.loc[df['cond'].str.contains('f'), 'principle'] += ' foreseen '\n",
    "    df.loc[df['cond'].str.contains('i'), 'principle'] += ' intended '\n",
    "    df.loc[df['cond'].str.contains('c'), 'principle'] += ' contact '\n",
    "    df.loc[~df['cond'].str.contains('c'), 'principle'] += ' no_contact '\n",
    "    df['yes'] = df['a'].str.contains(pat=r'\\b(yes)\\b', regex=True)\n",
    "    df['no'] = df['a'].str.contains(pat=r'\\b(no)\\b', regex=True)\n",
    "    df['unclear'] = df['yes'] == df['no']\n",
    "    df['val'] = None\n",
    "    df.loc[df['yes']==1, 'val'] = 'yes'\n",
    "    df.loc[df['no']==1, 'val'] = 'no'\n",
    "    df.loc[df['unclear']==1, 'val'] = 'unclear'\n",
    "    dfs_with_unclear.append(df.copy())\n",
    "    df = df[df['unclear']!=1] \n",
    "    dfs.append(df.copy())\n",
    "    \n",
    "df = pd.concat(dfs)\n",
    "df_with_unclear = pd.concat(dfs_with_unclear)\n",
    "\n",
    "def mean_by_exp_and_sub(df):\n",
    "    # set cond label and merge \n",
    "    exp = df['exp'].unique()\n",
    "    dfs = []\n",
    "    for e in exp:\n",
    "        d = df[df['exp']==e].groupby(['title', 'principle' ], as_index=False).mean()\n",
    "        d['exp'] = e\n",
    "        dfs.append(d.copy())\n",
    "\n",
    "    df2 = pd.concat(dfs)\n",
    "    return df2\n",
    "\n",
    "df2 = mean_by_exp_and_sub(df)\n",
    "df2_with_unclear = mean_by_exp_and_sub(df_with_unclear)\n",
    "\n",
    "    \n",
    "df[df['val']=='unclear'].to_excel(foldername[0] + '/unclear.xlsx')\n",
    "\n",
    "print('unclear proportion: ', np.mean(df_with_unclear[df_with_unclear.exp=='human']['unclear']==1))\n",
    "\n",
    "df = df[df['exp'] == 'human']\n",
    "\n",
    "df_with_unclear.prolific_id.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fig 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d = []\n",
    "#pairs = [('action', 'inaction'), ('intended', 'foreseen'), ('contact', 'no_contact')]\n",
    "#labels = ('action', 'intention', 'contact')\n",
    "#titles = [\n",
    "#    ('Boxcar', 'Pond', 'Ship', 'Car', 'Boat', 'Switch'),\n",
    "#    ('Speed', 'Burn', 'Boxcar', 'Switch', 'Chem', 'Shark'),\n",
    "#    ('Speed', 'Boxcar', 'Aqua', 'Rubble')\n",
    "#]\n",
    "#for p,l,t1 in zip(pairs, labels, titles):\n",
    "#    for t in t1:\n",
    "#        d.append({\n",
    "#            'principle': p[0],\n",
    "#            'item': t,\n",
    "#            'yes': df2.loc[(df2['title'] == t) * (df2['principle'].str.contains(' ' + p[0] + ' ')), 'yes'].mean()\n",
    "#        })\n",
    "#        d.append({\n",
    "#               'principle': p[1],\n",
    "#               'item': t,\n",
    "#               'yes': df2.loc[(df2['title'] == t) * (df2['principle'].str.contains(' ' + p[1] + ' ')), 'yes'].mean()\n",
    "#        })\n",
    "#\n",
    "#\n",
    "#new_df = pd.DataFrame(d)\n",
    "#new_df\n",
    "#\n",
    "#d = []\n",
    "#\n",
    "#for p,l,t1 in zip(pairs, labels, titles):\n",
    "#    for t in t1:\n",
    "#        d.append(\n",
    "#            {\n",
    "#                'principle': p[0],    \n",
    "#                'item': t,\n",
    "#                'replicates': df2.loc[(df2['title'] == t) * (df2['principle'].str.contains(' ' + p[1] + ' ')), 'yes'].mean() >\\\n",
    "#                            df2.loc[(df2['title'] == t) * (df2['principle'].str.contains(' ' + p[0] + ' ')), 'yes'].mean()\n",
    "#\n",
    "#            }\n",
    "#        )\n",
    "#df_table = pd.DataFrame(d)\n",
    "#df_table.loc[df_table['principle'] == 'intended', 'principle'] = 'intention'\n",
    "#print(df_table)\n",
    "#\n",
    "#\n",
    "df2 = df\n",
    "dv = 'yes'\n",
    "d = []\n",
    "pairs = [('action', 'inaction'), ('intended', 'foreseen'), ('contact', 'no_contact')]\n",
    "labels = ('action', 'intention', 'contact')\n",
    "titles = [\n",
    "    ('Boxcar', 'Pond', 'Ship', 'Car', 'Boat', 'Switch'),\n",
    "    ('Speed', 'Burn', 'Boxcar', 'Switch', 'Chem', 'Shark'),\n",
    "    ('Speed', 'Boxcar', 'Aqua', 'Rubble')\n",
    "]\n",
    "for p,l,t1 in zip(pairs, labels, titles):\n",
    "    for e in ['gpt-002', 'gpt-003', 'human']:\n",
    "        df2 = df[df['exp']==e]\n",
    "\n",
    "        if 'gpt' in e:\n",
    "            key = 'iter'\n",
    "            sub = df['iter'].unique()\n",
    "        else:\n",
    "            key = 'prolific_id'\n",
    "            sub = df['prolific_id'].unique()\n",
    "\n",
    "\n",
    "        for t in t1:\n",
    "            for i in sub:\n",
    "                if i in ['nan', np.NaN, 'notfound']:\n",
    "                    continue\n",
    "\n",
    "\n",
    "                d.append({\n",
    "                    'principle': p[0],\n",
    "                    'item': t,\n",
    "                    'val': df2.loc[(df2[key] == i) * (df2['title'] == t) * (df2['principle'].str.contains(' ' + p[0] + ' ')), dv].mean(),\n",
    "                    'meta_principle': l,\n",
    "                    key: i,\n",
    "                    'exp': e,\n",
    "                })\n",
    "                d.append({\n",
    "                       'principle': p[1],\n",
    "                       'item': t,\n",
    "                       'val': df2.loc[(df2[key]==i) * (df2['title'] == t) * (df2['principle'].str.contains(' ' + p[1] + ' ')), dv].mean(),\n",
    "                       'meta_principle': l,\n",
    "                       key: i,\n",
    "                        'exp': e,\n",
    "                })\n",
    "\n",
    "\n",
    "new_df = pd.DataFrame(d)\n",
    "\n",
    "d = []\n",
    "\n",
    "for p,l,t1 in zip(pairs, labels, titles):\n",
    "    for e in ['gpt-002', 'gpt-003', 'human']:\n",
    "        df2 = df[df['exp']==e]\n",
    "\n",
    "\n",
    "        for t in t1:\n",
    "            d.append(\n",
    "                {\n",
    "                    'principle': p[0],    \n",
    "                    'item': t,\n",
    "                    'replicates': df2.loc[(df2['title'] == t) * (df2['principle'].str.contains(' ' + p[1] + ' ')), dv].mean() >\\\n",
    "                                df2.loc[(df2['title'] == t) * (df2['principle'].str.contains(' ' + p[0] + ' ')), dv].mean(),\n",
    "                                'exp': e,\n",
    "\n",
    "                }\n",
    "            )\n",
    "df_table = pd.DataFrame(d)\n",
    "df_table.loc[df_table['principle'] == 'intended', 'principle'] = 'intention'\n",
    "print(df_table)\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fig 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(19, 12)})\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "df3 = new_df[new_df.exp=='human'].groupby(['principle', 'prolific_id', 'meta_principle'], as_index=False).mean()\n",
    "df3['principle_variation'] = 'yes'\n",
    "df3.loc[df3['principle'].isin(['no_contact', 'foreseen', 'inaction']), 'principle_variation'] = 'no'\n",
    "sns.stripplot(x='meta_principle', y='val', hue='principle_variation', data=df3, size=10, linewidth=1.2, zorder=2, edgecolor='white', dodge=True)\n",
    "sns.barplot(x='meta_principle', y='val', hue='principle_variation', ci=68,data=df3, alpha=.5, zorder=1, dodge=True)\n",
    "# raincloud(x='exp', y='yes', markersize=9, df=df2)\n",
    "x_lim = plt.gca().get_xlim()\n",
    "plt.plot(x_lim, [.5, .5], ls='--', color='gray', zorder=0)\n",
    "# plt.ylim(0.5,1.5)\n",
    "plt.xlabel('Principle pairs')\n",
    "plt.ylabel('Endorsement')\n",
    "plt.title('Human')\n",
    "\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "df3 = new_df[new_df.exp=='gpt-002'].groupby(['principle', 'iter', 'meta_principle'], as_index=False).mean()\n",
    "df3['principle_variation'] = 'yes'\n",
    "df3.loc[df3['principle'].isin(['no_contact', 'foreseen', 'inaction']), 'principle_variation'] = 'no'\n",
    "sns.stripplot(x='meta_principle', y='val', hue='principle_variation', data=df3, size=10, linewidth=1.2, zorder=2, edgecolor='white', dodge=True)\n",
    "sns.barplot(x='meta_principle', y='val', hue='principle_variation', data=df3, alpha=.5, zorder=1, ci=68, dodge=True)\n",
    "# raincloud(x='exp', y='yes', markersize=9, df=df2)\n",
    "x_lim = plt.gca().get_xlim()\n",
    "plt.plot(x_lim, [.5, .5], ls='--', color='gray', zorder=0)\n",
    "# plt.ylim(0.5,1.5)\n",
    "plt.xlabel('Principle pairs')\n",
    "plt.ylabel('Endorsement')\n",
    "plt.title('davinci-002')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "df3 = new_df[new_df.exp=='gpt-003'].groupby(['principle', 'iter', 'meta_principle'], as_index=False).mean()\n",
    "df3['principle_variation'] = 'yes'\n",
    "df3.loc[df3['principle'].isin(['no_contact', 'foreseen', 'inaction']), 'principle_variation'] = 'no'\n",
    "sns.stripplot(x='meta_principle', y='val', hue='principle_variation', data=df3, size=10, linewidth=1.2, zorder=2, edgecolor='white', dodge=True)\n",
    "sns.barplot(x='meta_principle', y='val', hue='principle_variation', data=df3, alpha=.5, zorder=1, ci=68, dodge=True)\n",
    "# raincloud(x='exp', y='yes', markersize=9, df=df2)\n",
    "x_lim = plt.gca().get_xlim()\n",
    "plt.plot(x_lim, [.5, .5], ls='--', color='gray', zorder=0)\n",
    "# plt.ylim(0.5,1.5)\n",
    "plt.xlabel('Principle pairs')\n",
    "plt.ylabel('Endorsement')\n",
    "plt.title('davinci-003')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df3 = new_df[new_df.exp=='human'].groupby(['principle', 'prolific_id', 'meta_principle'], as_index=False).mean()\n",
    "df3['principle_variation'] = 'yes'\n",
    "df3.loc[df3['principle'].isin(['no_contact', 'foreseen', 'inaction']), 'principle_variation'] = 'no'\n",
    "\n",
    "pg.ttest(x=df3[df3.principle_variation=='yes'][df3.meta_principle=='contact']['val'], y=df3[df3.principle_variation=='no'][df3.meta_principle=='contact']['val'], paired=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(14, 8)})\n",
    "\n",
    "order = ['action', 'inaction', 'intended', 'foreseen', 'contact', 'no_contact']\n",
    "df3 = new_df.groupby(['principle', 'item'], as_index=False).mean()\n",
    "\n",
    "sns.stripplot(x='principle', y='val', hue='item', data=df3,\n",
    "    size=10, linewidth=1.2, zorder=2, edgecolor='white', dodge=True, order=order)\n",
    "\n",
    "g = sns.barplot(x='principle', y='val', hue='item', data=df3,\n",
    "    alpha=.5, zorder=1, ci=68, dodge=True, order=order,)\n",
    "\n",
    "# s.legend_.show()\n",
    "# raincloud(x='exp', y='yes', markersize=9, df=df2)\n",
    "x_lim = plt.gca().get_xlim()\n",
    "plt.plot(x_lim, [.5, .5], ls='--', color='gray', zorder=0)\n",
    "# plt.ylim(0.5,7.5)\n",
    "plt.xlabel('Principle')\n",
    "plt.ylabel('Endorsement')\n",
    "\n",
    "h, l = g.get_legend_handles_labels()\n",
    "plt.legend(h[:12], l[:12], loc='lower right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def f(s, v, props): return np.where(s.isin([v]), props, '')\n",
    "s = df_table.style\n",
    "df_table1 = df_table[df_table['exp'] == 'human']\n",
    "df_table1.loc[df_table1['replicates']==True, 'replicates'] = '✅'\n",
    "df_table1.loc[df_table1['replicates']==False, 'replicates'] = '❌'\n",
    "\n",
    "df_table1\n",
    "# s.apply(f, v=True, props=\"color: lightgreen;\", axis=0)\\\n",
    "# .apply(f, v=False, props=\"color: white; background-color:pink\", axis=0)\n",
    "# df_table.style.apply(f, v=False, props=\"color:lightred;\", axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddd = df[(df.exp=='human') & (df.title=='Car')& (df.principle.str.contains('action'))]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d1d5f5d24c0beaf0f21a912d572161c07ffcd5b3d25f5387b55cec2718b20cad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
